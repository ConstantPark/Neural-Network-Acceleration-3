## Neural Network Acceleration Study Season #3
This is a repository of the study "neural network acceleration". The goal of this study is to understand the acceleration of nerual networks on various devices. The topic of acceleration includes `CPU`, `GPU`, `NPU`, `ASIC`, `FPGA`, and `NDP`. Our materials are open to this github and youtube. This study is supported by Facebook community, "AI Robitcs Korea".

#### CPU/GPU, NPU, and distributed computing
- Fast acceleration of inference/training on general processor (CPU/GPU)
- Distributed computing for large training system
- Heterogeneous system architecture (HSA) device

#### ASIC and FPGA
- Low-power inference acceleration using RTL/HLS design
- High computing performance interfence/training accelerator

#### Near-data Processing (NDP)
- Data processing unit for neural network acceleration (w/o HBM based accelerator)

## Paper List (16)
### CPU/GPU/NPU based Acceleration (?)

### Dedicated neural network accelerator (?)
	1. Integrating NVIDIA Deep Learning Accelerator (NVDLA) with RISC-V SoC on FireSim, EMC2, 2019

### NDP (?)

	
## Presentation with Video
### Week1: Introduction (September 09, 2020)
**Integrating NVIDIA Deep Learning Accelerator (NVDLA) with RISC-V SoC on FireSim**

	Presenter: 
	PPT: 
	Video: 




## Contributors
**Main Contributor**: Constant Park (sonicstage12@naver.com)

**Presenters**: Constant Park (sonicstage12@naver.com)
